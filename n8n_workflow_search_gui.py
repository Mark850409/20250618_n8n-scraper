#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
n8n Workflow æ™ºèƒ½æœå°‹èˆ‡æ•™å­¸ç”Ÿæˆç³»çµ± - Gradio GUI ç‰ˆæœ¬
åŸºæ–¼ LangChain + ChromaDB çš„å‘é‡æœå°‹å¼•æ“ï¼Œæä¾›ç¶²é ä»‹é¢
"""

import os
import json
import shutil
import gradio as gr
from typing import List, Dict, Any, Tuple
from datetime import datetime
import chromadb
import requests
import logging

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¯é¸ä¾è³´çš„å°å…¥
try:
    from dotenv import load_dotenv
    DOTENV_AVAILABLE = True
except ImportError:
    DOTENV_AVAILABLE = False
    logger.warning("python-dotenv æœªå®‰è£ï¼Œå°‡è·³é .env æ–‡ä»¶è¼‰å…¥")

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("openai å¥—ä»¶æœªå®‰è£ï¼ŒOpenAI åŠŸèƒ½å°‡ä¸å¯ç”¨")

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    logger.warning("google-generativeai å¥—ä»¶æœªå®‰è£ï¼ŒGemini åŠŸèƒ½å°‡ä¸å¯ç”¨")

try:
    from langchain_huggingface import HuggingFaceEmbeddings
    LANGCHAIN_HUGGINGFACE_AVAILABLE = True
except ImportError:
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        LANGCHAIN_HUGGINGFACE_AVAILABLE = True
    except ImportError:
        LANGCHAIN_HUGGINGFACE_AVAILABLE = False
        logger.warning("HuggingFace embeddings æœªå®‰è£ï¼Œå°‡ä½¿ç”¨ç°¡å–®æ–‡å­—æœå°‹")

try:
    from langchain_community.vectorstores import Chroma
    from langchain_core.documents import Document
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    logger.warning("langchain å¥—ä»¶æœªå®‰è£ï¼Œå°‡ä½¿ç”¨ç°¡å–®æ–‡å­—æœå°‹")

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
if DOTENV_AVAILABLE:
    load_dotenv()

class AITutorialGenerator:
    """AI æ•™å­¸ç”Ÿæˆå™¨"""

    def __init__(self):
        """åˆå§‹åŒ– AI æ•™å­¸ç”Ÿæˆå™¨"""
        self.provider = os.getenv('AI_PROVIDER', 'openai').lower()
        self.max_tokens = int(os.getenv('MAX_TOKENS', '2000'))
        self.temperature = float(os.getenv('TEMPERATURE', '0.7'))
        self.available = False

        # åˆå§‹åŒ–å°æ‡‰çš„ AI æœå‹™
        self.init_ai_service()

    def init_ai_service(self):
        """åˆå§‹åŒ– AI æœå‹™"""
        try:
            if self.provider == 'openai':
                if not OPENAI_AVAILABLE:
                    logger.error("OpenAI å¥—ä»¶æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ OpenAI æœå‹™")
                    return

                api_key = os.getenv('OPENAI_API_KEY')
                if not api_key:
                    logger.error("æœªè¨­å®š OPENAI_API_KEY")
                    return

                base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
                self.model = os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')
                self.openai_client = OpenAI(api_key=api_key, base_url=base_url)
                self.available = True
                logger.info(f"å·²åˆå§‹åŒ– OpenAI æœå‹™ï¼Œæ¨¡å‹ï¼š{self.model}")

            elif self.provider == 'gemini':
                if not GEMINI_AVAILABLE:
                    logger.error("Gemini å¥—ä»¶æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ Gemini æœå‹™")
                    return

                api_key = os.getenv('GEMINI_API_KEY')
                if api_key:
                    genai.configure(api_key=api_key)
                    self.model = os.getenv('GEMINI_MODEL', 'gemini-pro')
                    self.available = True
                    logger.info(f"å·²åˆå§‹åŒ– Gemini æœå‹™ï¼Œæ¨¡å‹ï¼š{self.model}")
                else:
                    logger.error("æœªè¨­å®š GEMINI_API_KEY")

            elif self.provider == 'ollama':
                self.base_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
                self.model = os.getenv('OLLAMA_MODEL', 'llama2')
                self.available = True
                logger.info(f"å·²åˆå§‹åŒ– Ollama æœå‹™ï¼Œæ¨¡å‹ï¼š{self.model}")

            else:
                logger.error(f"ä¸æ”¯æ´çš„ AI æä¾›å•†ï¼š{self.provider}")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ– AI æœå‹™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            self.available = False

    def generate_tutorial(self, question: str) -> str:
        """
        ç”Ÿæˆ n8n ç¯€é»æ•™å­¸

        Args:
            question: ç”¨æˆ¶å•é¡Œ

        Returns:
            str: ç”Ÿæˆçš„æ•™å­¸å…§å®¹
        """
        if not self.available:
            return """âŒ AI æ•™å­¸ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨

å¯èƒ½çš„åŸå› ï¼š
1. ç¼ºå°‘å¿…è¦çš„ AI å¥—ä»¶ (openai, google-generativeai)
2. æœªè¨­å®š API é‡‘é‘°
3. AI æœå‹™åˆå§‹åŒ–å¤±æ•—

è«‹æª¢æŸ¥ç’°å¢ƒè®Šæ•¸è¨­å®šæˆ–å®‰è£å¿…è¦çš„ä¾è³´å¥—ä»¶ã€‚"""

        try:
            # æ§‹å»ºæç¤ºè©
            prompt = self.build_prompt(question)

            # æ ¹æ“šæä¾›å•†èª¿ç”¨å°æ‡‰çš„ API
            if self.provider == 'openai':
                return self.call_openai(prompt)
            elif self.provider == 'gemini':
                return self.call_gemini(prompt)
            elif self.provider == 'ollama':
                return self.call_ollama(prompt)
            else:
                return "âŒ ä¸æ”¯æ´çš„ AI æä¾›å•†"

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ•™å­¸æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return f"âŒ ç”Ÿæˆæ•™å­¸æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

    def build_prompt(self, question: str) -> str:
        """æ§‹å»ºæç¤ºè©"""
        return f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ n8n å·¥ä½œæµç¨‹è‡ªå‹•åŒ–å°ˆå®¶ã€‚è«‹æ ¹æ“šç”¨æˆ¶çš„å•é¡Œï¼Œæä¾›è©³ç´°ã€å¯¦ç”¨çš„ n8n ç¯€é»è¨­å®šæ•™å­¸ã€‚

ç”¨æˆ¶å•é¡Œï¼š{question}

è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

## ğŸ“‹ ç¯€é»æ¦‚è¿°
ç°¡è¦ä»‹ç´¹ç›¸é—œç¯€é»çš„åŠŸèƒ½å’Œç”¨é€”

## ğŸ› ï¸ è©³ç´°è¨­å®šæ­¥é©Ÿ
æä¾›é€æ­¥çš„è¨­å®šæŒ‡å—ï¼ŒåŒ…æ‹¬ï¼š
1. å¦‚ä½•æ·»åŠ ç¯€é»
2. å¿…è¦çš„åƒæ•¸è¨­å®š
3. èªè­‰è¨­å®šï¼ˆå¦‚æœéœ€è¦ï¼‰
4. æ¸¬è©¦æ–¹æ³•

## ğŸ’¡ å¯¦ç”¨ç¯„ä¾‹
æä¾›ä¸€å€‹å…·é«”çš„ä½¿ç”¨å ´æ™¯å’Œè¨­å®šç¯„ä¾‹

## âš ï¸ æ³¨æ„äº‹é …
åˆ—å‡ºå¸¸è¦‹å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆ

## ğŸ”— ç›¸é—œè³‡æº
æä¾›ç›¸é—œçš„å®˜æ–¹æ–‡æª”é€£çµ

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œå…§å®¹è¦è©³ç´°ä¸”å¯¦ç”¨ã€‚"""

    def call_openai(self, prompt: str) -> str:
        """èª¿ç”¨ OpenAI API"""
        try:
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ n8n å·¥ä½œæµç¨‹è‡ªå‹•åŒ–å°ˆå®¶ï¼Œæ“…é•·æä¾›è©³ç´°çš„æŠ€è¡“æ•™å­¸ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"èª¿ç”¨ OpenAI API æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return f"âŒ OpenAI API èª¿ç”¨å¤±æ•—ï¼š{str(e)}"

    def call_gemini(self, prompt: str) -> str:
        """èª¿ç”¨ Gemini API"""
        try:
            model = genai.GenerativeModel(self.model)
            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=self.max_tokens,
                    temperature=self.temperature
                )
            )
            return response.text
        except Exception as e:
            logger.error(f"èª¿ç”¨ Gemini API æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return f"âŒ Gemini API èª¿ç”¨å¤±æ•—ï¼š{str(e)}"

    def call_ollama(self, prompt: str) -> str:
        """èª¿ç”¨ Ollama API"""
        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": self.temperature,
                        "num_predict": self.max_tokens
                    }
                }
            )
            response.raise_for_status()
            return response.json()['response']
        except Exception as e:
            logger.error(f"èª¿ç”¨ Ollama API æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return f"âŒ Ollama API èª¿ç”¨å¤±æ•—ï¼š{str(e)}"

class N8nWorkflowSearcherGUI:
    """n8n Workflow æœå°‹èˆ‡æ•™å­¸ç”Ÿæˆç³»çµ± - GUI ç‰ˆæœ¬"""
    
    def __init__(self, workflows_dir: str = ".", chroma_db_path: str = "./chroma_db"):
        """
        åˆå§‹åŒ–æœå°‹ç³»çµ±
        
        Args:
            workflows_dir: workflow JSON æª”æ¡ˆæ‰€åœ¨ç›®éŒ„
            chroma_db_path: ChromaDB è³‡æ–™åº«è·¯å¾‘
        """
        self.workflows_dir = workflows_dir
        self.chroma_db_path = chroma_db_path
        self.selected_dir = "selected_workflows"
        
        # å»ºç«‹å¿…è¦ç›®éŒ„
        os.makedirs(self.selected_dir, exist_ok=True)
        os.makedirs(chroma_db_path, exist_ok=True)
        
        # åˆå§‹åŒ– Embedding æ¨¡å‹
        logger.info("æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹...")
        self.embeddings = None

        if LANGCHAIN_HUGGINGFACE_AVAILABLE:
            try:
                self.embeddings = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                    model_kwargs={'device': 'cpu'}
                )
                logger.info("æˆåŠŸè¼‰å…¥ HuggingFace Embedding æ¨¡å‹")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥ HuggingFace æ¨¡å‹ï¼Œä½¿ç”¨ç°¡å–®çš„æ–‡å­—åŒ¹é…: {e}")
                self.embeddings = None
        else:
            logger.info("HuggingFace embeddings ä¸å¯ç”¨ï¼Œä½¿ç”¨ç°¡å–®æ–‡å­—æœå°‹æ¨¡å¼")
        
        # åˆå§‹åŒ– ChromaDB
        self.chroma_client = chromadb.PersistentClient(path=chroma_db_path)
        self.collection_name = "n8n_workflows"

        # å„²å­˜æœå°‹çµæœä¾›å¾ŒçºŒä½¿ç”¨
        self.current_results = []

        # ç°¡å–®æœå°‹æ¨¡å¼çš„è³‡æ–™å„²å­˜
        self.simple_workflows = []

        # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
        self.vectorstore = None
        self.init_vectorstore()
    
    def init_vectorstore(self):
        """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
        if self.embeddings is None:
            logger.info("ä½¿ç”¨ç°¡å–®æ–‡å­—æœå°‹æ¨¡å¼")
            self.vectorstore = None
            self.build_simple_index()
            return

        try:
            # æ¯æ¬¡å•Ÿå‹•éƒ½é‡æ–°å»ºç«‹ç´¢å¼•ä»¥ç¢ºä¿è³‡æ–™æ˜¯æœ€æ–°çš„
            logger.info("é‡æ–°æƒæä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«ç´¢å¼•...")

            # å…ˆæ¸…é™¤ç¾æœ‰çš„ collectionï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                self.chroma_client.delete_collection(self.collection_name)
                logger.info("å·²æ¸…é™¤èˆŠçš„å‘é‡è³‡æ–™åº«")
            except Exception:
                logger.info("æ²’æœ‰æ‰¾åˆ°èˆŠçš„å‘é‡è³‡æ–™åº«ï¼Œå°‡å»ºç«‹æ–°çš„")

            # é‡æ–°å»ºç«‹ç´¢å¼•
            self.build_index()

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å‘é‡è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            logger.info("å»ºç«‹æ–°çš„å‘é‡è³‡æ–™åº«...")
            self.build_index()

    def build_simple_index(self):
        """å»ºç«‹ç°¡å–®çš„æ–‡å­—æœå°‹ç´¢å¼•"""
        logger.info("é‡æ–°æƒæä¸¦å»ºç«‹ç°¡å–®æœå°‹ç´¢å¼•...")

        # æ¸…ç©ºç¾æœ‰ç´¢å¼•
        self.simple_workflows = []

        # æƒææ‰€æœ‰ JSON æª”æ¡ˆ
        json_files = []
        for root, _, files in os.walk(self.workflows_dir):
            for file in files:
                if file.endswith('.json') and not file.startswith('.'):
                    json_files.append(os.path.join(root, file))

        logger.info(f"æ‰¾åˆ° {len(json_files)} å€‹ JSON æª”æ¡ˆ")

        # ä½¿ç”¨å­—å…¸ä¾†å»é‡ï¼Œä»¥æª”æ¡ˆè·¯å¾‘ç‚ºéµ
        workflows_dict = {}

        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    workflow_data = json.load(f)

                # æå–å·¥ä½œæµç¨‹è³‡è¨Š
                workflow_info = self.extract_workflow_info(workflow_data, os.path.basename(json_file))
                workflow_info['file_path'] = json_file

                # ä½¿ç”¨æª”æ¡ˆè·¯å¾‘ä½œç‚ºå”¯ä¸€éµä¾†å»é‡
                workflows_dict[json_file] = workflow_info

            except Exception as e:
                logger.warning(f"è™•ç†æª”æ¡ˆ {json_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue

        # å°‡å»é‡å¾Œçš„å·¥ä½œæµç¨‹è½‰æ›ç‚ºåˆ—è¡¨
        self.simple_workflows = list(workflows_dict.values())
        logger.info(f"æˆåŠŸå»ºç«‹ç°¡å–®æœå°‹ç´¢å¼•ï¼ŒåŒ…å« {len(self.simple_workflows)} ç­†è³‡æ–™")

        # èª¿è©¦ï¼šé¡¯ç¤ºå‰å¹¾å€‹å·¥ä½œæµç¨‹çš„è³‡è¨Šå’Œæª¢æŸ¥é‡è¤‡
        logger.info("æª¢æŸ¥å·¥ä½œæµç¨‹åˆ—è¡¨æ˜¯å¦æœ‰é‡è¤‡...")
        file_paths = [w['file_path'] for w in self.simple_workflows]
        unique_paths = set(file_paths)
        if len(file_paths) != len(unique_paths):
            logger.warning(f"ç™¼ç¾é‡è¤‡é …ç›®ï¼ç¸½æ•¸: {len(file_paths)}, å”¯ä¸€æ•¸: {len(unique_paths)}")
            # æ‰¾å‡ºé‡è¤‡çš„è·¯å¾‘
            from collections import Counter
            path_counts = Counter(file_paths)
            duplicates = [path for path, count in path_counts.items() if count > 1]
            logger.warning(f"é‡è¤‡çš„æª”æ¡ˆè·¯å¾‘: {duplicates}")
        else:
            logger.info("å·¥ä½œæµç¨‹åˆ—è¡¨ç„¡é‡è¤‡é …ç›®")

        for i, workflow in enumerate(self.simple_workflows[:3]):
            logger.info(f"å·¥ä½œæµç¨‹ {i+1}: {workflow['name']}")
            logger.info(f"  æª”æ¡ˆè·¯å¾‘: {workflow['file_path']}")
            logger.info(f"  æè¿°: {workflow['description'][:100]}...")
            logger.info(f"  ç¯€é»é¡å‹ (å‰5å€‹): {workflow['node_types'][:5]}")
            logger.info(f"  æ‰€æœ‰ç¯€é»é¡å‹: {workflow['node_types']}")
    
    def extract_workflow_info(self, workflow_data: Dict[str, Any], filename: str) -> Dict[str, Any]:
        """
        å¾ workflow JSON ä¸­æå–é—œéµè³‡è¨Š
        
        Args:
            workflow_data: workflow JSON è³‡æ–™
            filename: æª”æ¡ˆåç¨±
            
        Returns:
            Dict: æå–çš„å·¥ä½œæµç¨‹è³‡è¨Š
        """
        # åŸºæœ¬è³‡è¨Š
        workflow_id = workflow_data.get('id', 'unknown')
        workflow_name = workflow_data.get('name', 'Unnamed Workflow')
        
        # ç¯€é»è³‡æ–™ç›´æ¥åœ¨æ ¹å±¤ç´š
        nodes = workflow_data.get('nodes', [])
        
        # æå–ç¯€é»çµæ§‹
        node_structure = []
        for node in nodes:
            node_name = node.get('name', 'Unknown Node')
            node_type = node.get('type', 'unknown')
            node_structure.append(f"{node_name}ï¼ˆ{node_type}ï¼‰")
        
        # ç”Ÿæˆæè¿°æ–‡å­—ï¼ˆç”¨æ–¼æœå°‹ï¼‰
        description_parts = [
            workflow_name,
            f"å·¥ä½œæµç¨‹åŒ…å« {len(nodes)} å€‹ç¯€é»",
            "ç¯€é»é¡å‹ï¼š" + "ã€".join([node.get('type', 'unknown') for node in nodes[:5]])
        ]
        
        # æ ¹æ“šç¯€é»é¡å‹æ¨æ¸¬åŠŸèƒ½
        node_types = [node.get('type', '') for node in nodes]
        if any('trigger' in nt.lower() for nt in node_types):
            description_parts.append("åŒ…å«è§¸ç™¼å™¨")
        if any('http' in nt.lower() for nt in node_types):
            description_parts.append("åŒ…å«HTTPè«‹æ±‚")
        if any('email' in nt.lower() for nt in node_types):
            description_parts.append("åŒ…å«éƒµä»¶åŠŸèƒ½")
        if any('discord' in nt.lower() for nt in node_types):
            description_parts.append("åŒ…å«Discordé€šçŸ¥")
        if any('schedule' in nt.lower() for nt in node_types):
            description_parts.append("åŒ…å«å®šæ™‚æ’ç¨‹")
        
        return {
            'id': workflow_id,
            'name': workflow_name,
            'filename': filename,
            'description': "ï¼›".join(description_parts),
            'node_structure': node_structure,
            'node_count': len(nodes),
            'node_types': node_types,
            'raw_data': workflow_data
        }
    
    def build_index(self):
        """å»ºç«‹å‘é‡è³‡æ–™åº«ç´¢å¼•"""
        if not LANGCHAIN_AVAILABLE:
            logger.warning("LangChain ä¸å¯ç”¨ï¼Œè·³éå‘é‡ç´¢å¼•å»ºç«‹")
            return

        logger.info("é–‹å§‹æƒæ workflow æª”æ¡ˆ...")

        documents = []

        # æƒææ‰€æœ‰ JSON æª”æ¡ˆ
        json_files = []
        for root, _, files in os.walk(self.workflows_dir):
            for file in files:
                if file.endswith('.json') and not file.startswith('.'):
                    json_files.append(os.path.join(root, file))

        logger.info(f"æ‰¾åˆ° {len(json_files)} å€‹ JSON æª”æ¡ˆ")

        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    workflow_data = json.load(f)

                # æå–å·¥ä½œæµç¨‹è³‡è¨Š
                workflow_info = self.extract_workflow_info(workflow_data, os.path.basename(json_file))

                # å»ºç«‹æ–‡æª”å…§å®¹ï¼ˆç”¨æ–¼å‘é‡æœå°‹ï¼‰
                doc_content = f"""
                å·¥ä½œæµç¨‹åç¨±ï¼š{workflow_info['name']}
                æè¿°ï¼š{workflow_info['description']}
                ç¯€é»çµæ§‹ï¼š{'; '.join(workflow_info['node_structure'][:10])}
                """

                # å»ºç«‹ Document ä¸¦åŒ…å« metadata
                doc_metadata = {
                    'filename': workflow_info['filename'],
                    'workflow_id': str(workflow_info['id']),
                    'name': workflow_info['name'],
                    'description': workflow_info['description'],
                    'node_structure': str(workflow_info['node_structure']),
                    'node_count': workflow_info['node_count'],
                    'file_path': json_file
                }
                documents.append(Document(page_content=doc_content, metadata=doc_metadata))

            except Exception as e:
                logger.warning(f"è™•ç†æª”æ¡ˆ {json_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue

        if documents:
            try:
                # å»ºç«‹å‘é‡è³‡æ–™åº«
                self.vectorstore = Chroma.from_documents(
                    documents=documents,
                    embedding=self.embeddings,
                    collection_name=self.collection_name,
                    persist_directory=self.chroma_db_path
                )
                logger.info(f"æˆåŠŸå»ºç«‹å‘é‡ç´¢å¼•ï¼ŒåŒ…å« {len(documents)} ç­†è³‡æ–™")

            except Exception as e:
                error_msg = str(e).lower()
                if "already exists" in error_msg or "collection" in error_msg:
                    logger.info(f"é›†åˆå·²å­˜åœ¨ï¼Œå˜—è©¦è¼‰å…¥ç¾æœ‰é›†åˆ: {e}")
                    try:
                        # å˜—è©¦è¼‰å…¥ç¾æœ‰çš„å‘é‡è³‡æ–™åº«
                        self.vectorstore = Chroma(
                            collection_name=self.collection_name,
                            embedding_function=self.embeddings,
                            persist_directory=self.chroma_db_path
                        )
                        logger.info("æˆåŠŸè¼‰å…¥ç¾æœ‰å‘é‡è³‡æ–™åº«")
                    except Exception as load_error:
                        logger.error(f"è¼‰å…¥ç¾æœ‰å‘é‡è³‡æ–™åº«å¤±æ•—: {load_error}")
                        # å˜—è©¦é‡ç½®ä¸¦é‡æ–°å»ºç«‹
                        try:
                            logger.info("å˜—è©¦é‡ç½®å‘é‡è³‡æ–™åº«...")
                            self.chroma_client.delete_collection(self.collection_name)
                            self.vectorstore = Chroma.from_documents(
                                documents=documents,
                                embedding=self.embeddings,
                                collection_name=self.collection_name,
                                persist_directory=self.chroma_db_path
                            )
                            logger.info(f"é‡ç½®å¾ŒæˆåŠŸå»ºç«‹å‘é‡ç´¢å¼•ï¼ŒåŒ…å« {len(documents)} ç­†è³‡æ–™")
                        except Exception as reset_error:
                            logger.error(f"é‡ç½®å‘é‡è³‡æ–™åº«å¤±æ•—: {reset_error}")
                            raise
                else:
                    logger.error(f"å»ºç«‹å‘é‡è³‡æ–™åº«æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
                    raise
        else:
            logger.error("æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ workflow æª”æ¡ˆ")
    
    def search_workflows(self, query: str, top_k: int = 5) -> List[Tuple[Dict[str, Any], float]]:
        """
        æœå°‹ç›¸ä¼¼çš„å·¥ä½œæµç¨‹

        Args:
            query: æœå°‹æŸ¥è©¢
            top_k: å›å‚³å‰ N ç­†çµæœ

        Returns:
            List: æœå°‹çµæœåˆ—è¡¨ï¼ŒåŒ…å« (metadata, similarity_score)
        """
        if self.vectorstore is None:
            # ä½¿ç”¨ç°¡å–®æ–‡å­—æœå°‹
            return self.simple_text_search(query, top_k)

        try:
            # åŸ·è¡Œç›¸ä¼¼åº¦æœå°‹
            results = self.vectorstore.similarity_search_with_score(query, k=top_k)

            search_results = []
            for doc, score in results:
                # å–å¾— metadata
                metadata = doc.metadata
                # ChromaDB ä½¿ç”¨é¤˜å¼¦è·é›¢ï¼Œè·é›¢è¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜
                if score <= 1.0:
                    similarity = 1.0 - score
                else:
                    similarity = 1.0 / (1.0 + score)

                # ç¢ºä¿ç›¸ä¼¼åº¦åœ¨åˆç†ç¯„åœå…§
                similarity = max(0.0, min(1.0, similarity))
                search_results.append((metadata, similarity))

            # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼ˆé«˜åˆ°ä½ï¼‰
            search_results.sort(key=lambda x: x[1], reverse=True)

            return search_results

        except Exception as e:
            logger.error(f"æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def simple_text_search(self, query: str, top_k: int = 5) -> List[Tuple[Dict[str, Any], float]]:
        """
        ç°¡å–®çš„æ–‡å­—æœå°‹

        Args:
            query: æœå°‹æŸ¥è©¢
            top_k: å›å‚³å‰ N ç­†çµæœ

        Returns:
            List: æœå°‹çµæœåˆ—è¡¨ï¼ŒåŒ…å« (metadata, similarity_score)
        """
        logger.info(f"åŸ·è¡Œç°¡å–®æ–‡å­—æœå°‹ï¼ŒæŸ¥è©¢ï¼š'{query}'ï¼Œè³‡æ–™åº«åŒ…å« {len(self.simple_workflows)} ç­†è³‡æ–™")

        query_lower = query.lower()
        search_results = []
        seen_workflows = set()  # ç”¨æ–¼å»é‡

        # å°‡æŸ¥è©¢åˆ†è§£ç‚ºé—œéµå­—
        query_keywords = [kw.strip() for kw in query_lower.split() if kw.strip()]

        for workflow in self.simple_workflows:
            # ä½¿ç”¨æª”æ¡ˆè·¯å¾‘ä½œç‚ºå”¯ä¸€æ¨™è­˜ç¬¦ä¾†é¿å…é‡è¤‡
            workflow_id = workflow['file_path']
            if workflow_id in seen_workflows:
                continue

            # è¨ˆç®—æ–‡å­—åŒ¹é…åº¦
            score = 0.0

            # æª¢æŸ¥åç¨±åŒ¹é…
            name_lower = workflow['name'].lower()
            for keyword in query_keywords:
                if keyword in name_lower:
                    score += 0.5

            # æª¢æŸ¥æè¿°åŒ¹é…
            desc_lower = workflow['description'].lower()
            for keyword in query_keywords:
                if keyword in desc_lower:
                    score += 0.3

            # æª¢æŸ¥ç¯€é»é¡å‹åŒ¹é…ï¼ˆé¿å…é‡è¤‡è¨ˆåˆ†ï¼‰
            node_type_matches = set()
            for node_type in workflow['node_types']:
                node_type_lower = node_type.lower()
                for keyword in query_keywords:
                    if keyword in node_type_lower and keyword not in node_type_matches:
                        score += 0.2
                        node_type_matches.add(keyword)

            # æª¢æŸ¥æª”æ¡ˆååŒ¹é…
            filename_lower = workflow['filename'].lower()
            for keyword in query_keywords:
                if keyword in filename_lower:
                    score += 0.1

            # ç‰¹æ®Šé—œéµå­—åŒ¹é…ï¼ˆé¿å…é‡è¤‡è¨ˆåˆ†ï¼‰
            special_matches = {
                'telegram': ['telegram'],
                'bot': ['telegram', 'bot'],
                'discord': ['discord'],
                'email': ['email', 'mail'],
                'weather': ['weather', 'openweathermap'],
                'schedule': ['schedule', 'trigger'],
                'http': ['http', 'request'],
                'api': ['http', 'api'],
                'notification': ['discord', 'telegram', 'email'],
                'é€šçŸ¥': ['discord', 'telegram', 'email'],
                'æ©Ÿå™¨äºº': ['telegram', 'bot'],
                'å¤©æ°£': ['weather', 'openweathermap'],
                'æ’ç¨‹': ['schedule', 'trigger'],
                'å®šæ™‚': ['schedule', 'trigger'],
                'è‡ªå‹•å›è¦†': ['telegram', 'bot'],
                'å›è¦†': ['telegram', 'bot']
            }

            special_score_added = set()
            for keyword in query_keywords:
                if keyword in special_matches:
                    for match_type in special_matches[keyword]:
                        if match_type not in special_score_added:
                            for node_type in workflow['node_types']:
                                if match_type.lower() in node_type.lower():
                                    score += 0.4
                                    special_score_added.add(match_type)
                                    break

            # å¦‚æœæœ‰ä»»ä½•åŒ¹é…ï¼ŒåŠ å…¥çµæœ
            if score > 0:
                search_results.append((workflow, score))
                seen_workflows.add(workflow_id)
                logger.info(f"æ‰¾åˆ°åŒ¹é…ï¼š{workflow['name']} (åˆ†æ•¸: {score:.2f})")

        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼ˆé«˜åˆ°ä½ï¼‰
        search_results.sort(key=lambda x: x[1], reverse=True)

        # ç¢ºä¿è¿”å›è¶³å¤ çš„çµæœï¼Œå¦‚æœä¸è¶³å‰‡è£œå……å…¶ä»–å·¥ä½œæµç¨‹
        if len(search_results) < top_k:
            # å‰µå»ºä¸€å€‹å»é‡çš„å·¥ä½œæµç¨‹åˆ—è¡¨
            unique_workflows = []
            seen_paths = set()
            for workflow in self.simple_workflows:
                if workflow['file_path'] not in seen_paths:
                    unique_workflows.append(workflow)
                    seen_paths.add(workflow['file_path'])

            for workflow in unique_workflows:
                if len(search_results) >= top_k:
                    break
                workflow_id = workflow['file_path']
                if workflow_id not in seen_workflows:
                    search_results.append((workflow, 0.0))
                    seen_workflows.add(workflow_id)
                    logger.info(f"è£œå……çµæœï¼š{workflow['name']} (åˆ†æ•¸: 0.00)")

        logger.info(f"æœå°‹å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} å€‹çµæœ")
        return search_results[:top_k]

    def format_search_results(self, results: List[Tuple[Dict[str, Any], float]], query: str) -> str:
        """
        æ ¼å¼åŒ–æœå°‹çµæœç‚º HTML é¡¯ç¤º

        Args:
            results: æœå°‹çµæœ
            query: åŸå§‹æŸ¥è©¢

        Returns:
            str: æ ¼å¼åŒ–çš„ HTML çµæœ
        """
        if not results:
            return "âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„å·¥ä½œæµç¨‹ï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—"

        html_content = f"""
        <div style="font-family: Arial, sans-serif;">
            <h3>ğŸ” æœå°‹çµæœ</h3>
            <p><strong>æœå°‹é—œéµå­—ï¼š</strong>{query}</p>
            <p><strong>æ‰¾åˆ° {len(results)} å€‹ç›¸é—œå·¥ä½œæµç¨‹</strong></p>
            <hr>
        """

        for i, (metadata, similarity) in enumerate(results, 1):
            # è§£æç¯€é»çµæ§‹
            node_structure_str = metadata.get('node_structure', '[]')
            try:
                import ast
                if isinstance(node_structure_str, str):
                    node_structure = ast.literal_eval(node_structure_str)
                else:
                    node_structure = node_structure_str
            except:
                node_structure = []

            # é¡¯ç¤ºç¯€é»çµæ§‹ï¼ˆå‰10å€‹ï¼‰
            nodes_display = ""
            for j, node in enumerate(node_structure[:10]):
                if j == 0:
                    nodes_display += f"<li><strong>Triggerï¼š</strong>{node}</li>"
                else:
                    nodes_display += f"<li>{node}</li>"

            if len(node_structure) > 10:
                nodes_display += f"<li><em>... é‚„æœ‰ {len(node_structure) - 10} å€‹ç¯€é»</em></li>"

            html_content += f"""
            <div style="border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;">
                <h4>[{i}] {metadata['name']}</h4>
                <p><strong>ğŸ§  ç›¸ä¼¼åº¦ï¼š</strong>{similarity:.4f}</p>
                <p><strong>ğŸ“ ä¾†æºæª”æ¡ˆï¼š</strong>{metadata['filename']}</p>
                <p><strong>ğŸ“– æè¿°ï¼š</strong>{metadata['description']}</p>
                <p><strong>ğŸ§© Workflow çµæ§‹ï¼š</strong></p>
                <ul style="margin-left: 20px;">
                    {nodes_display}
                </ul>
            </div>
            """

        html_content += "</div>"
        return html_content

    def search_and_display(self, query: str, top_k: int = 5) -> Tuple[str, gr.update]:
        """
        åŸ·è¡Œæœå°‹ä¸¦è¿”å›çµæœï¼ŒåŒæ™‚æ›´æ–°ä¸‹æ‹‰é¸å–®

        Args:
            query: æœå°‹æŸ¥è©¢
            top_k: å›å‚³å‰ N ç­†çµæœ

        Returns:
            Tuple: (æœå°‹çµæœHTML, æ›´æ–°çš„ä¸‹æ‹‰é¸å–®)
        """
        if not query.strip():
            return "è«‹è¼¸å…¥æœå°‹é—œéµå­—", gr.update(choices=[], value=None)

        # åŸ·è¡Œæœå°‹
        self.current_results = self.search_workflows(query, top_k)

        # æ ¼å¼åŒ–çµæœ
        html_results = self.format_search_results(self.current_results, query)

        # æº–å‚™ä¸‹æ‹‰é¸å–®é¸é …
        if self.current_results:
            choices = [f"[{i}] {metadata['name']}" for i, (metadata, _) in enumerate(self.current_results, 1)]
            dropdown_update = gr.update(choices=choices, value=None, visible=True)
        else:
            dropdown_update = gr.update(choices=[], value=None, visible=False)

        return html_results, dropdown_update

    def save_selected_workflow(self, selected_workflow: str) -> tuple[str, str]:
        """
        å„²å­˜é¸ä¸­çš„å·¥ä½œæµç¨‹ä¸¦è¿”å›æ•™å­¸æ–‡ä»¶å…§å®¹

        Args:
            selected_workflow: é¸ä¸­çš„å·¥ä½œæµç¨‹ï¼ˆæ ¼å¼ï¼š[1] å·¥ä½œæµç¨‹åç¨±ï¼‰

        Returns:
            tuple: (å„²å­˜çµæœè¨Šæ¯, æ•™å­¸æ–‡ä»¶å…§å®¹)
        """
        if not selected_workflow or not self.current_results:
            return "âŒ è«‹å…ˆæœå°‹ä¸¦é¸æ“‡ä¸€å€‹å·¥ä½œæµç¨‹", ""

        try:
            # è§£æé¸æ“‡çš„ç´¢å¼•
            index = int(selected_workflow.split(']')[0].replace('[', '')) - 1

            if index < 0 or index >= len(self.current_results):
                return "âŒ é¸æ“‡çš„å·¥ä½œæµç¨‹ç´¢å¼•ç„¡æ•ˆ", ""

            metadata, _ = self.current_results[index]

            # å„²å­˜å·¥ä½œæµç¨‹
            success, tutorial_content = self.save_workflow_files(metadata)

            if success:
                save_message = f"âœ… æˆåŠŸå„²å­˜å·¥ä½œæµç¨‹ã€Œ{metadata['name']}ã€ï¼\nğŸ“ æª”æ¡ˆå·²å„²å­˜åˆ° selected_workflows/ ç›®éŒ„"
                return save_message, tutorial_content
            else:
                return "âŒ å„²å­˜å·¥ä½œæµç¨‹æ™‚ç™¼ç”ŸéŒ¯èª¤", ""

        except Exception as e:
            logger.error(f"å„²å­˜å·¥ä½œæµç¨‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"âŒ å„²å­˜å¤±æ•—ï¼š{str(e)}", ""

    def save_workflow_files(self, metadata: Dict[str, Any]) -> tuple[bool, str]:
        """
        å„²å­˜å·¥ä½œæµç¨‹æª”æ¡ˆï¼ˆJSON å’Œ Markdownï¼‰

        Args:
            metadata: å·¥ä½œæµç¨‹ metadata

        Returns:
            tuple: (æ˜¯å¦å„²å­˜æˆåŠŸ, æ•™å­¸å…§å®¹)
        """
        try:
            source_file = metadata['file_path']
            original_filename = metadata['filename']
            workflow_name = metadata['name']

            # æ¸…ç†æª”æ¡ˆåç¨±ä¸­çš„ç‰¹æ®Šå­—å…ƒ
            safe_workflow_name = self.sanitize_filename(workflow_name)
            safe_original_name = os.path.splitext(original_filename)[0]

            # è¤‡è£½ JSON æª”æ¡ˆåˆ° selected_workflows ç›®éŒ„
            new_json_filename = f"workflow_{safe_original_name}.json"
            dest_json = os.path.join(self.selected_dir, new_json_filename)
            shutil.copy2(source_file, dest_json)

            # ç”Ÿæˆæ•™å­¸ Markdown æª”æ¡ˆ
            tutorial_filename = f"workflow_{safe_workflow_name}.md"
            tutorial_path = os.path.join(self.selected_dir, tutorial_filename)

            tutorial_content = self.generate_tutorial_markdown(metadata, source_file)

            with open(tutorial_path, 'w', encoding='utf-8') as f:
                f.write(tutorial_content)

            logger.info(f"æˆåŠŸå„²å­˜å·¥ä½œæµç¨‹ï¼šJSON={dest_json}, MD={tutorial_path}")
            return True, tutorial_content

        except Exception as e:
            logger.error(f"å„²å­˜å·¥ä½œæµç¨‹æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False, ""

    def sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤ä¸åˆæ³•çš„å­—å…ƒ"""
        import re
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'[ğŸ¤–ğŸš˜ğŸ“²ğŸ’¡ğŸ”§ğŸ“ŒğŸ“ğŸ“–ğŸ§©]', '', filename)
        filename = filename.strip()
        if len(filename) > 50:
            filename = filename[:50]
        return filename

    def generate_tutorial_markdown(self, metadata: Dict[str, Any], file_path: str) -> str:
        """
        ç”Ÿæˆæ•™å­¸èªªæ˜ Markdown æª”æ¡ˆ

        Args:
            metadata: å·¥ä½œæµç¨‹ metadata
            file_path: åŸå§‹ JSON æª”æ¡ˆè·¯å¾‘

        Returns:
            str: ç”Ÿæˆçš„ Markdown å…§å®¹
        """
        # è®€å–åŸå§‹ JSON æª”æ¡ˆä»¥ç²å–è©³ç´°è³‡è¨Š
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                workflow_data = json.load(f)
        except Exception as e:
            logger.error(f"è®€å–æª”æ¡ˆ {file_path} å¤±æ•—: {e}")
            workflow_data = {}

        # ç¯€é»è³‡æ–™ç›´æ¥åœ¨æ ¹å±¤ç´š
        nodes = workflow_data.get('nodes', [])

        # ç”Ÿæˆ Markdown å…§å®¹
        markdown_content = f"""# {metadata['name']} - å·¥ä½œæµç¨‹æ•™å­¸

## ğŸ“‹ åŸºæœ¬è³‡è¨Š

- **å·¥ä½œæµç¨‹åç¨±**: {metadata['name']}
- **å·¥ä½œæµç¨‹ ID**: {metadata.get('workflow_id', 'N/A')}
- **ç¯€é»æ•¸é‡**: {metadata.get('node_count', 0)}
- **ä¾†æºæª”æ¡ˆ**: {metadata['filename']}
- **ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“– å·¥ä½œæµç¨‹æè¿°

{metadata['description']}

"""

        # ç”Ÿæˆè©³ç´°è¨­å®šæ­¥é©Ÿ
        setup_steps = self.generate_setup_steps(nodes)

        # æ·»åŠ å»ºè­°ç”¨é€”
        markdown_content += f"""{setup_steps}

## ğŸ’¡ å»ºè­°ç”¨é€”èˆ‡å»¶ä¼¸æ‡‰ç”¨

### é©ç”¨å ´æ™¯
{self.generate_use_cases(nodes)}

### å»¶ä¼¸æ‡‰ç”¨å»ºè­°
{self.generate_extensions(nodes)}

## ğŸ”§ è¨­å®šæ³¨æ„äº‹é …

1. **èªè­‰è¨­å®š**: è«‹ç¢ºä¿æ‰€æœ‰éœ€è¦èªè­‰çš„ç¯€é»éƒ½å·²æ­£ç¢ºè¨­å®š API é‡‘é‘°æˆ–èªè­‰è³‡è¨Š
2. **è§¸ç™¼æ¢ä»¶**: æª¢æŸ¥è§¸ç™¼å™¨çš„è¨­å®šæ˜¯å¦ç¬¦åˆæ‚¨çš„éœ€æ±‚
3. **éŒ¯èª¤è™•ç†**: å»ºè­°ç‚ºé—œéµç¯€é»æ·»åŠ éŒ¯èª¤è™•ç†é‚è¼¯
4. **æ¸¬è©¦åŸ·è¡Œ**: åœ¨æ­£å¼ä½¿ç”¨å‰ï¼Œè«‹å…ˆé€²è¡Œæ¸¬è©¦åŸ·è¡Œ

## ğŸ“š ç›¸é—œè³‡æº

- [n8n å®˜æ–¹æ–‡æª”](https://docs.n8n.io/)
- [n8n ç¤¾ç¾¤ç¯„ä¾‹](https://n8n.io/workflows/)
- [ç¯€é»åƒè€ƒæ–‡æª”](https://docs.n8n.io/integrations/)

---
*æ­¤æ•™å­¸æª”æ¡ˆç”± n8n Workflow æ™ºèƒ½æœå°‹ç³»çµ±è‡ªå‹•ç”Ÿæˆ*
"""

        return markdown_content

    def generate_use_cases(self, nodes: List[Dict[str, Any]]) -> str:
        """æ ¹æ“šç¯€é»é¡å‹ç”Ÿæˆä½¿ç”¨å ´æ™¯å»ºè­°"""
        node_types = [node.get('type', '') for node in nodes]
        use_cases = []

        if any('schedule' in nt.lower() for nt in node_types):
            use_cases.append("- å®šæœŸè‡ªå‹•åŒ–ä»»å‹™ï¼ˆå¦‚æ¯æ—¥å ±å‘Šã€å®šæ™‚å‚™ä»½ï¼‰")
        if any('http' in nt.lower() for nt in node_types):
            use_cases.append("- API è³‡æ–™æ•´åˆèˆ‡åŒæ­¥")
            use_cases.append("- ç¬¬ä¸‰æ–¹æœå‹™æ•´åˆ")
        if any('email' in nt.lower() for nt in node_types):
            use_cases.append("- è‡ªå‹•åŒ–éƒµä»¶é€šçŸ¥ç³»çµ±")
            use_cases.append("- å ±å‘Šèˆ‡è­¦å‘Šç™¼é€")
        if any('discord' in nt.lower() or 'slack' in nt.lower() for nt in node_types):
            use_cases.append("- åœ˜éšŠå”ä½œé€šçŸ¥")
            use_cases.append("- ç³»çµ±ç›£æ§è­¦å‘Š")
        if any('webhook' in nt.lower() for nt in node_types):
            use_cases.append("- å³æ™‚äº‹ä»¶éŸ¿æ‡‰")
            use_cases.append("- å¤–éƒ¨ç³»çµ±æ•´åˆè§¸ç™¼")

        return "\n".join(use_cases) if use_cases else "- é€šç”¨è‡ªå‹•åŒ–å·¥ä½œæµç¨‹"

    def generate_extensions(self, nodes: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆå»¶ä¼¸æ‡‰ç”¨å»ºè­°"""
        extensions = [
            "- æ·»åŠ éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶",
            "- æ•´åˆæ›´å¤šé€šçŸ¥ç®¡é“ï¼ˆå¦‚ LINEã€WeChatï¼‰",
            "- åŠ å…¥è³‡æ–™æŒä¹…åŒ–å­˜å„²",
            "- å¯¦ä½œæ¢ä»¶åˆ†æ”¯è™•ç†ä¸åŒæƒ…æ³",
            "- æ·»åŠ æ—¥èªŒè¨˜éŒ„å’Œç›£æ§åŠŸèƒ½"
        ]
        return "\n".join(extensions)

    def generate_setup_steps(self, nodes: List[Dict[str, Any]]) -> str:
        """
        æ ¹æ“šå¯¦éš›ç¯€é»ç”Ÿæˆè©³ç´°çš„è¨­å®šæ­¥é©Ÿ

        Args:
            nodes: ç¯€é»åˆ—è¡¨

        Returns:
            str: è¨­å®šæ­¥é©Ÿèªªæ˜
        """
        steps = []
        step_count = 1

        # åˆ†æå·¥ä½œæµç¨‹çš„å¯¦éš›çµæ§‹ï¼Œç”Ÿæˆå°æ‡‰çš„æ“ä½œæ­¥é©Ÿ
        for i, node in enumerate(nodes, 1):
            node_name = node.get('name', f'ç¯€é» {i}')
            node_type = node.get('type', 'unknown')
            parameters = node.get('parameters', {})

            steps.append(f"### æ­¥é©Ÿ {step_count}ï¼šè¨­å®š {node_name}")
            step_count += 1

            # æ ¹æ“šç¯€é»é¡å‹ç”Ÿæˆå…·é«”çš„è¨­å®šæ­¥é©Ÿ
            if 'trigger' in node_type.lower():
                if 'schedule' in node_type.lower():
                    steps.append("1. åœ¨å·¥ä½œæµç¨‹çš„ç•«å¸ƒä¸Šï¼Œæ‹–æ›³ã€ŒSchedule Triggerã€ç¯€é»")
                    steps.append("2. é»æ“Šç¯€é»ï¼Œä¸¦è¨­å®šè§¸ç™¼é »ç‡ï¼š")
                    steps.append("   - **Mode**: é¸æ“‡ã€ŒEvery Dayã€")
                    steps.append("   - **Time**: è¨­å®šæ‚¨å¸Œæœ›è§¸ç™¼çš„æ™‚é–“ï¼Œä¾‹å¦‚ã€Œ08:00ã€")
                    steps.append("3. é»æ“Šã€ŒExecute Nodeã€ä¾†æ¸¬è©¦é€™å€‹ç¯€é»ï¼Œç¢ºä¿å®ƒèƒ½æ­£å¸¸é‹ä½œ")
                elif 'telegram' in node_type.lower():
                    steps.append("1. æ‹–æ›³ã€ŒTelegram Triggerã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                    steps.append("2. è¨­å®š Telegram Bot è§¸ç™¼å™¨ï¼š")
                    if 'updates' in parameters:
                        updates = parameters.get('updates', [])
                        if 'message' in updates:
                            steps.append("   - **Updates**: é¸æ“‡ã€Œmessageã€ä¾†æ¥æ”¶è¨Šæ¯")
                        if 'callback_query' in updates:
                            steps.append("   - **Updates**: é¸æ“‡ã€Œcallback_queryã€ä¾†æ¥æ”¶æŒ‰éˆ•å›èª¿")
                    steps.append("3. åœ¨æ†‘è­‰ç®¡ç†ä¸­è¨­å®š Telegram Bot Token")
                elif 'webhook' in node_type.lower():
                    steps.append("1. æ‹–æ›³ã€ŒWebhookã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                    steps.append("2. è¨­å®š Webhook åƒæ•¸ï¼š")
                    steps.append("   - **HTTP Method**: é¸æ“‡é©ç•¶çš„æ–¹æ³•ï¼ˆGET/POSTï¼‰")
                    steps.append("   - **Path**: è¨­å®š webhook è·¯å¾‘")
                    steps.append("3. å„²å­˜ä¸¦å•Ÿç”¨å·¥ä½œæµç¨‹ä»¥ç²å¾— webhook URL")
                elif 'gmail' in node_type.lower():
                    steps.append("1. æ‹–æ›³ã€ŒGmail Triggerã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                    steps.append("2. è¨­å®š Gmail è§¸ç™¼å™¨ï¼š")
                    steps.append("   - **Event**: é¸æ“‡è§¸ç™¼äº‹ä»¶ï¼ˆå¦‚æ–°éƒµä»¶ï¼‰")
                    steps.append("3. åœ¨æ†‘è­‰ç®¡ç†ä¸­è¨­å®š Gmail OAuth2 èªè­‰")

            elif 'httpRequest' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒHTTP Requestã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. é»æ“Šç¯€é»ï¼Œç„¶å¾Œè¨­å®šï¼š")
                if 'method' in parameters:
                    method = parameters.get('method', 'GET')
                    steps.append(f"   - **Method**: é¸æ“‡ã€Œ{method}ã€")
                if 'url' in parameters:
                    steps.append("   - **URL**: è¼¸å…¥ API ç«¯é» URL")
                if 'sendHeaders' in parameters or 'headerParameters' in parameters:
                    steps.append("   - **Headers**: è¨­å®šå¿…è¦çš„è«‹æ±‚æ¨™é ­")
                if 'sendBody' in parameters:
                    steps.append("   - **Body**: è¨­å®šè«‹æ±‚ä¸»é«”å…§å®¹")
                steps.append("3. æ¸¬è©¦ç¯€é»ç¢ºä¿ API è«‹æ±‚æ­£å¸¸é‹ä½œ")

            elif 'telegram' in node_type.lower() and 'trigger' not in node_type.lower():
                steps.append("1. æ‹–æ›³ã€ŒTelegramã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®š Telegram è¨Šæ¯ç™¼é€ï¼š")
                if 'text' in parameters:
                    steps.append("   - **Text**: è¨­å®šè¦ç™¼é€çš„è¨Šæ¯å…§å®¹")
                if 'chatId' in parameters:
                    steps.append("   - **Chat ID**: è¨­å®šç›®æ¨™èŠå¤©å®¤ ID")
                if 'resource' in parameters and parameters.get('resource') == 'file':
                    steps.append("   - **Resource**: é¸æ“‡ã€Œfileã€ä¾†ä¸‹è¼‰æª”æ¡ˆ")
                    if 'fileId' in parameters:
                        steps.append("   - **File ID**: è¨­å®šè¦ä¸‹è¼‰çš„æª”æ¡ˆ ID")
                steps.append("3. åœ¨æ†‘è­‰ç®¡ç†ä¸­è¨­å®š Telegram Bot Token")

            elif 'googleSheets' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒGoogle Sheetsã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®š Google Sheets æ“ä½œï¼š")
                if 'operation' in parameters:
                    operation = parameters.get('operation', 'read')
                    steps.append(f"   - **Operation**: é¸æ“‡ã€Œ{operation}ã€")
                if 'documentId' in parameters:
                    steps.append("   - **Document ID**: è¼¸å…¥ Google Sheets æ–‡ä»¶ ID")
                if 'sheetName' in parameters:
                    steps.append("   - **Sheet Name**: é¸æ“‡è¦æ“ä½œçš„å·¥ä½œè¡¨")
                steps.append("3. åœ¨æ†‘è­‰ç®¡ç†ä¸­è¨­å®š Google Sheets OAuth2 èªè­‰")

            elif 'code' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒCodeã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®š JavaScript ç¨‹å¼ç¢¼ï¼š")
                steps.append("   - **JavaScript Code**: è¼¸å…¥è‡ªå®šç¾©çš„è™•ç†é‚è¼¯")
                steps.append("3. æ¸¬è©¦ç¨‹å¼ç¢¼ç¢ºä¿é‚è¼¯æ­£ç¢º")

            elif 'set' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒSetã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®šè³‡æ–™è™•ç†ï¼š")
                if 'assignments' in parameters:
                    steps.append("   - **Assignments**: è¨­å®šè¦ä¿®æ”¹æˆ–æ–°å¢çš„è³‡æ–™æ¬„ä½")
                steps.append("3. æ¸¬è©¦ç¯€é»ç¢ºä¿è³‡æ–™è™•ç†æ­£ç¢º")

            elif 'switch' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒSwitchã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®šæ¢ä»¶åˆ†æ”¯ï¼š")
                if 'rules' in parameters:
                    steps.append("   - **Rules**: è¨­å®šåˆ¤æ–·æ¢ä»¶å’Œå°æ‡‰çš„è¼¸å‡ºè·¯å¾‘")
                steps.append("3. æ¸¬è©¦å„å€‹åˆ†æ”¯è·¯å¾‘")

            elif 'wait' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒWaitã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®šç­‰å¾…æ™‚é–“ï¼š")
                if 'amount' in parameters:
                    amount = parameters.get('amount', 1)
                    steps.append(f"   - **Amount**: è¨­å®šç­‰å¾…æ™‚é–“ç‚º {amount} ç§’")
                steps.append("3. æ ¹æ“šéœ€è¦èª¿æ•´ç­‰å¾…æ™‚é–“")

            elif 'merge' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒMergeã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®šè³‡æ–™åˆä½µæ–¹å¼ï¼š")
                if 'mode' in parameters:
                    mode = parameters.get('mode', 'append')
                    steps.append(f"   - **Mode**: é¸æ“‡ã€Œ{mode}ã€åˆä½µæ¨¡å¼")
                steps.append("3. é€£æ¥å¤šå€‹è¼¸å…¥ç¯€é»åˆ°æ­¤åˆä½µç¯€é»")

            elif 'splitOut' in node_type:
                steps.append("1. æ‹–æ›³ã€ŒSplit Outã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®šè³‡æ–™åˆ†å‰²ï¼š")
                if 'fieldToSplitOut' in parameters:
                    field = parameters.get('fieldToSplitOut', '')
                    steps.append(f"   - **Field to Split Out**: è¨­å®šè¦åˆ†å‰²çš„æ¬„ä½ã€Œ{field}ã€")
                steps.append("3. æ¸¬è©¦è³‡æ–™åˆ†å‰²çµæœ")

            elif 'langchain' in node_type.lower():
                steps.append("1. æ‹–æ›³ LangChain ç›¸é—œç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. è¨­å®š AI æ¨¡å‹åƒæ•¸ï¼š")
                if 'model' in parameters:
                    model = parameters.get('model', {})
                    if isinstance(model, dict) and 'value' in model:
                        steps.append(f"   - **Model**: é¸æ“‡ã€Œ{model['value']}ã€")
                if 'text' in parameters:
                    steps.append("   - **Text**: è¨­å®šè¼¸å…¥æ–‡æœ¬")
                if 'messages' in parameters:
                    steps.append("   - **Messages**: è¨­å®šå°è©±è¨Šæ¯")
                steps.append("3. åœ¨æ†‘è­‰ç®¡ç†ä¸­è¨­å®šç›¸æ‡‰çš„ API é‡‘é‘°")

            else:
                # é€šç”¨è¨­å®šæ­¥é©Ÿ
                steps.append(f"1. æ‹–æ›³ã€Œ{node_name}ã€ç¯€é»åˆ°å·¥ä½œæµç¨‹ç•«å¸ƒä¸Š")
                steps.append("2. é»æ“Šç¯€é»é€²è¡Œè¨­å®šï¼š")
                if parameters:
                    main_params = list(parameters.keys())[:3]
                    for param in main_params:
                        steps.append(f"   - **{param}**: æ ¹æ“šéœ€æ±‚è¨­å®šæ­¤åƒæ•¸")
                steps.append("3. æ¸¬è©¦ç¯€é»ç¢ºä¿è¨­å®šæ­£ç¢º")

            steps.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”

        if not steps:
            return ""

        return f"""## ğŸ› ï¸ è©³ç´°è¨­å®šæ­¥é©Ÿ

{chr(10).join(steps)}"""

def create_gradio_interface():
    """å‰µå»º Gradio ä»‹é¢"""

    # åˆå§‹åŒ–æœå°‹ç³»çµ±å’Œ AI æ•™å­¸ç”Ÿæˆå™¨
    searcher = N8nWorkflowSearcherGUI()
    ai_generator = AITutorialGenerator()

    # å‰µå»º Gradio ä»‹é¢
    with gr.Blocks(
        title="n8n Workflow æ™ºèƒ½æœå°‹èˆ‡æ•™å­¸ç”Ÿæˆç³»çµ±",
        theme=gr.themes.Base(
            primary_hue="blue",
            secondary_hue="gray",
            neutral_hue="slate"
        ).set(
            body_background_fill="*neutral_950",
            body_text_color="*neutral_100",
            background_fill_primary="*neutral_900",
            background_fill_secondary="*neutral_800",
            border_color_primary="*neutral_700",
            block_background_fill="*neutral_900",
            block_border_color="*neutral_700",
            input_background_fill="*neutral_800",
            input_border_color="*neutral_600",
            button_primary_background_fill="*primary_600",
            button_primary_background_fill_hover="*primary_700",
            button_secondary_background_fill="*neutral_700",
            button_secondary_background_fill_hover="*neutral_600"
        ),
        css="""
        .gradio-container {
            max-width: 1200px !important;
            background-color: #0f172a !important;
            color: #f1f5f9 !important;
        }
        .search-results {
            max-height: 600px;
            overflow-y: auto;
            background-color: #1e293b !important;
            border: 1px solid #475569 !important;
            border-radius: 8px;
            padding: 15px;
        }
        .tutorial-content {
            max-height: 800px;
            overflow-y: auto;
            border: 1px solid #475569 !important;
            border-radius: 8px;
            padding: 20px;
            background-color: #1e293b !important;
            color: #f1f5f9 !important;
        }
        .tutorial-content h1 {
            color: #60a5fa !important;
            border-bottom: 2px solid #3b82f6 !important;
            padding-bottom: 10px;
        }
        .tutorial-content h2 {
            color: #94a3b8 !important;
            margin-top: 25px;
        }
        .tutorial-content h3 {
            color: #cbd5e1 !important;
            margin-top: 20px;
        }
        .tutorial-content code {
            background-color: #374151 !important;
            color: #fbbf24 !important;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
        .tutorial-content ul, .tutorial-content ol {
            color: #e2e8f0 !important;
        }
        .tutorial-content li {
            margin-bottom: 5px;
        }
        .tutorial-content p {
            color: #e2e8f0 !important;
            line-height: 1.6;
        }
        .tutorial-content strong {
            color: #fbbf24 !important;
        }
        .tutorial-content em {
            color: #a78bfa !important;
        }
        /* ä¿®å¾©æœå°‹çµæœçš„é¡¯ç¤º */
        .search-results h3, .search-results h4 {
            color: #60a5fa !important;
        }
        .search-results p {
            color: #e2e8f0 !important;
        }
        .search-results strong {
            color: #fbbf24 !important;
        }
        .search-results ul, .search-results li {
            color: #cbd5e1 !important;
        }
        /* è¼¸å…¥æ¡†å’ŒæŒ‰éˆ•æ¨£å¼ */
        .gr-textbox, .gr-dropdown {
            background-color: #374151 !important;
            border-color: #6b7280 !important;
            color: #f9fafb !important;
        }
        .gr-button {
            background-color: #4f46e5 !important;
            border-color: #4f46e5 !important;
            color: white !important;
        }
        .gr-button:hover {
            background-color: #4338ca !important;
        }
        """
    ) as demo:

        gr.Markdown("""
        # ğŸ¤– n8n Workflow æ™ºèƒ½æœå°‹èˆ‡æ•™å­¸ç”Ÿæˆç³»çµ±

        å°ˆæ¥­çš„ n8n å·¥ä½œæµç¨‹æœå°‹èˆ‡ AI æ•™å­¸ç”Ÿæˆå¹³å°
        """)

        # å‰µå»ºé ç±¤
        with gr.Tabs():
            # ç¬¬ä¸€å€‹é ç±¤ï¼šå·¥ä½œæµç¨‹æœå°‹
            with gr.TabItem("ğŸ” n8n Workflow æ™ºèƒ½æœå°‹"):
                gr.Markdown("""
                ## ğŸ’¡ ä½¿ç”¨èªªæ˜
                1. åœ¨ä¸‹æ–¹è¼¸å…¥æ¡†ä¸­æè¿°æ‚¨æƒ³è¦å¯¦ä½œçš„å·¥ä½œæµç¨‹
                2. é»æ“Šã€Œæœå°‹ã€æŒ‰éˆ•æŸ¥æ‰¾ç›¸é—œçš„å·¥ä½œæµç¨‹
                3. å¾æœå°‹çµæœä¸­é¸æ“‡åˆé©çš„å·¥ä½œæµç¨‹
                4. é»æ“Šã€Œå„²å­˜é¸ä¸­çš„å·¥ä½œæµç¨‹ã€ç”Ÿæˆæ•™å­¸æ–‡ä»¶

                ### ğŸ“ æœå°‹ç¯„ä¾‹ï¼š
                - æ¯å¤©æ—©ä¸Šå¯„å‡ºæ°£è±¡é€šçŸ¥
                - ç›£æ§ä¼ºæœå™¨ç•°å¸¸ç™¼ Discord è­¦å‘Š
                - å®šæ™‚å‚™ä»½è³‡æ–™åº«ä¸¦ç™¼é€å ±å‘Š
                - Telegram Bot è‡ªå‹•å›è¦†
                """)

                with gr.Row():
                    with gr.Column(scale=3):
                        # æœå°‹è¼¸å…¥
                        search_input = gr.Textbox(
                            label="ğŸ” è«‹æè¿°æ‚¨æƒ³è¦å¯¦ä½œçš„å·¥ä½œæµç¨‹",
                            placeholder="ä¾‹å¦‚ï¼šæ¯å¤©æ—©ä¸Šå¯„å‡ºæ°£è±¡é€šçŸ¥",
                            lines=2
                        )

                        # æœå°‹æŒ‰éˆ•
                        search_btn = gr.Button("ğŸ” æœå°‹å·¥ä½œæµç¨‹", variant="primary", size="lg")

                    with gr.Column(scale=1):
                        # çµæœæ•¸é‡é¸æ“‡
                        top_k = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=5,
                            step=1,
                            label="é¡¯ç¤ºçµæœæ•¸é‡",
                            info="æœ€å¤šé¡¯ç¤ºå¹¾å€‹æœå°‹çµæœ"
                        )

                # æœå°‹çµæœé¡¯ç¤º
                search_results = gr.HTML(
                    label="æœå°‹çµæœ",
                    elem_classes=["search-results"]
                )

                # å·¥ä½œæµç¨‹é¸æ“‡ä¸‹æ‹‰é¸å–®
                workflow_dropdown = gr.Dropdown(
                    label="ğŸ“¥ é¸æ“‡è¦å„²å­˜çš„å·¥ä½œæµç¨‹",
                    choices=[],
                    visible=False,
                    interactive=True
                )

                # å„²å­˜æŒ‰éˆ•
                save_btn = gr.Button("ğŸ’¾ å„²å­˜é¸ä¸­çš„å·¥ä½œæµç¨‹", variant="secondary", visible=False)

                # å„²å­˜çµæœé¡¯ç¤º
                save_result = gr.Textbox(
                    label="å„²å­˜çµæœ",
                    visible=False,
                    interactive=False
                )

                # æ•™å­¸æ–‡ä»¶é¡¯ç¤º
                tutorial_display = gr.Markdown(
                    label="ğŸ“– å·¥ä½œæµç¨‹æ•™å­¸æ–‡ä»¶",
                    visible=False,
                    elem_classes=["tutorial-content"]
                )

            # ç¬¬äºŒå€‹é ç±¤ï¼šAI æ•™å­¸ç”Ÿæˆ
            with gr.TabItem("ğŸ¤– n8n Workflow æ•™å­¸ç”Ÿæˆ"):
                gr.Markdown("""
                ## ğŸ“ AI æ•™å­¸ç”Ÿæˆèªªæ˜
                é€éå¤§èªè¨€æ¨¡å‹ç‚ºæ‚¨æä¾›å°ˆæ¥­çš„ n8n ç¯€é»è¨­å®šæ•™å­¸èˆ‡æŒ‡å°

                ### ğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š
                1. åœ¨ä¸‹æ–¹è¼¸å…¥æ‚¨çš„å•é¡Œæˆ–éœ€è¦äº†è§£çš„ç¯€é»
                2. é¸æ“‡ AI æ¨¡å‹ï¼ˆå·²åœ¨ .env æª”æ¡ˆä¸­è¨­å®šï¼‰
                3. é»æ“Šã€Œç”Ÿæˆæ•™å­¸ã€ç²å¾—è©³ç´°çš„è¨­å®šæŒ‡å°

                ### ğŸ“ å•é¡Œç¯„ä¾‹ï¼š
                - OpenWeather ç¯€é»è©²å¦‚ä½•è¨­å®šï¼Ÿ
                - å¦‚ä½•è¨­å®š Telegram Bot è‡ªå‹•å›è¦†ï¼Ÿ
                - Discord Webhook ç¯€é»çš„åƒæ•¸è¨­å®š
                - Google Sheets ç¯€é»å¦‚ä½•é€£æ¥å’Œæ“ä½œï¼Ÿ
                - HTTP Request ç¯€é»çš„èªè­‰è¨­å®š
                """)

                with gr.Row():
                    with gr.Column(scale=4):
                        # å•é¡Œè¼¸å…¥
                        question_input = gr.Textbox(
                            label="ğŸ¤” è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ",
                            placeholder="ä¾‹å¦‚ï¼šOpenWeather ç¯€é»è©²å¦‚ä½•è¨­å®šï¼Ÿ",
                            lines=3
                        )

                    with gr.Column(scale=1):
                        # AI æ¨¡å‹è³‡è¨Šé¡¯ç¤º
                        ai_info = gr.Markdown(
                            f"""
                            **ğŸ¤– ç•¶å‰ AI è¨­å®š**
                            - æä¾›å•†ï¼š{ai_generator.provider.upper()}
                            - æ¨¡å‹ï¼š{getattr(ai_generator, 'model', 'N/A')}
                            - æœ€å¤§ Tokenï¼š{ai_generator.max_tokens}
                            - æº«åº¦ï¼š{ai_generator.temperature}

                            *è¨­å®šå¯åœ¨ .env æª”æ¡ˆä¸­ä¿®æ”¹*
                            """
                        )

                # ç”ŸæˆæŒ‰éˆ•
                generate_btn = gr.Button("ğŸ“ ç”Ÿæˆæ•™å­¸", variant="primary", size="lg")

                # æ•™å­¸å…§å®¹é¡¯ç¤º
                tutorial_output = gr.Markdown(
                    label="ğŸ“š AI ç”Ÿæˆçš„æ•™å­¸å…§å®¹",
                    elem_classes=["tutorial-content"]
                )

        # äº‹ä»¶è™•ç†
        def on_search(query, k):
            html_results, dropdown_update = searcher.search_and_display(query, k)

            # æ ¹æ“šæ˜¯å¦æœ‰çµæœä¾†æ±ºå®šé¡¯ç¤ºå“ªäº›å…ƒä»¶
            if searcher.current_results:
                return (
                    html_results,
                    dropdown_update,
                    gr.update(visible=True),  # save_btn
                    gr.update(visible=False), # save_result
                    gr.update(visible=False)  # tutorial_display
                )
            else:
                return (
                    html_results,
                    dropdown_update,
                    gr.update(visible=False), # save_btn
                    gr.update(visible=False), # save_result
                    gr.update(visible=False)  # tutorial_display
                )

        def on_save(selected_workflow):
            if not selected_workflow:
                return (
                    gr.update(value="âŒ è«‹å…ˆé¸æ“‡ä¸€å€‹å·¥ä½œæµç¨‹", visible=True),
                    gr.update(visible=False)
                )

            save_message, tutorial_content = searcher.save_selected_workflow(selected_workflow)

            if tutorial_content:
                return (
                    gr.update(value=save_message, visible=True),
                    gr.update(value=tutorial_content, visible=True)
                )
            else:
                return (
                    gr.update(value=save_message, visible=True),
                    gr.update(visible=False)
                )

        # AI æ•™å­¸ç”Ÿæˆäº‹ä»¶è™•ç†
        def on_generate_tutorial(question):
            if not question.strip():
                return "âŒ è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ"

            try:
                # é¡¯ç¤ºè¼‰å…¥ä¸­çš„è¨Šæ¯
                loading_message = "ğŸ¤– AI æ­£åœ¨ç”Ÿæˆæ•™å­¸å…§å®¹ï¼Œè«‹ç¨å€™..."

                # ç”Ÿæˆæ•™å­¸å…§å®¹
                tutorial_content = ai_generator.generate_tutorial(question)

                return tutorial_content

            except Exception as e:
                logger.error(f"ç”Ÿæˆæ•™å­¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                return f"âŒ ç”Ÿæˆæ•™å­¸æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

        # ç¶å®šäº‹ä»¶
        search_btn.click(
            fn=on_search,
            inputs=[search_input, top_k],
            outputs=[search_results, workflow_dropdown, save_btn, save_result, tutorial_display]
        )

        # æ”¯æ´ Enter éµæœå°‹
        search_input.submit(
            fn=on_search,
            inputs=[search_input, top_k],
            outputs=[search_results, workflow_dropdown, save_btn, save_result, tutorial_display]
        )

        save_btn.click(
            fn=on_save,
            inputs=[workflow_dropdown],
            outputs=[save_result, tutorial_display]
        )

        # ç¶å®š AI æ•™å­¸ç”Ÿæˆäº‹ä»¶
        generate_btn.click(
            fn=on_generate_tutorial,
            inputs=[question_input],
            outputs=[tutorial_output]
        )

        # æ”¯æ´ Enter éµç”Ÿæˆæ•™å­¸
        question_input.submit(
            fn=on_generate_tutorial,
            inputs=[question_input],
            outputs=[tutorial_output]
        )

        # é è…³è³‡è¨Š
        gr.Markdown("""
        ---
        ### ğŸ“š ç›¸é—œè³‡æº
        - [n8n å®˜æ–¹æ–‡æª”](https://docs.n8n.io/)
        - [n8n ç¤¾ç¾¤ç¯„ä¾‹](https://n8n.io/workflows/)
        - [ç¯€é»åƒè€ƒæ–‡æª”](https://docs.n8n.io/integrations/)

        *ç”± n8n Workflow æ™ºèƒ½æœå°‹ç³»çµ±æä¾›æ”¯æ´*
        """)

    return demo

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰ workflow æª”æ¡ˆ
        current_dir = "."
        json_files = []
        for _, _, files in os.walk(current_dir):
            for file in files:
                if file.endswith('.json') and not file.startswith('.'):
                    json_files.append(file)

        if not json_files:
            print("âŒ åœ¨ç•¶å‰ç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ° JSON æª”æ¡ˆ")
            print("ğŸ’¡ è«‹ç¢ºä¿æ‚¨çš„ workflow JSON æª”æ¡ˆåœ¨ç•¶å‰ç›®éŒ„æˆ–å­ç›®éŒ„ä¸­")
            return

        print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} å€‹ JSON æª”æ¡ˆ")

        # å‰µå»ºä¸¦å•Ÿå‹• Gradio ä»‹é¢
        demo = create_gradio_interface()

        # å•Ÿå‹•ä»‹é¢
        try:
            demo.launch(
                server_name="0.0.0.0",  # å…è¨±å¤–éƒ¨è¨ªå•
                server_port=7862,       # ä½¿ç”¨ä¸åŒç«¯å£é¿å…è¡çª
                share=False,            # ä¸å‰µå»ºå…¬é–‹é€£çµ
                debug=False,            # ç”Ÿç”¢ç’°å¢ƒé—œé–‰ debug
                show_error=True,        # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
                inbrowser=False,        # ä¸è‡ªå‹•é–‹å•Ÿç€è¦½å™¨
                quiet=True              # æ¸›å°‘è¼¸å‡ºè¨Šæ¯
            )
        except Exception as e:
            logger.error(f"Gradio å•Ÿå‹•å¤±æ•—: {e}")
            print(f"âŒ Gradio å•Ÿå‹•å¤±æ•—: {e}")
            print("å˜—è©¦ä½¿ç”¨å‚™ç”¨é…ç½®...")
            try:
                demo.launch(
                    server_name="127.0.0.1",  # åƒ…æœ¬åœ°è¨ªå•
                    server_port=7862,
                    share=False,
                    debug=False,
                    inbrowser=False,
                    quiet=True
                )
            except Exception as e2:
                logger.error(f"å‚™ç”¨é…ç½®ä¹Ÿå¤±æ•—: {e2}")
                print(f"âŒ ç„¡æ³•å•Ÿå‹•æ‡‰ç”¨: {e2}")

    except Exception as e:
        logger.error(f"å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"âŒ å•Ÿå‹•å¤±æ•—ï¼š{e}")

if __name__ == "__main__":
    main()
